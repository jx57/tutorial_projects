{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "Tagged sentences:  3914\n",
      "Tagged words: 100676\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    " \n",
    "print(tagged_sentences[0])\n",
    "print(\"Tagged sentences: \", len(tagged_sentences))\n",
    "print(\"Tagged words:\", len(nltk.corpus.treebank.tagged_words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorillard' 'Inc.' ',' 'the' 'unit' 'of' 'New' 'York-based' 'Loews'\n",
      " 'Corp.' 'that' '*T*-2' 'makes' 'Kent' 'cigarettes' ',' 'stopped' 'using'\n",
      " 'crocidolite' 'in' 'its' 'Micronite' 'cigarette' 'filters' 'in' '1956'\n",
      " '.']\n",
      "['NNP' 'NNP' ',' 'DT' 'NN' 'IN' 'JJ' 'JJ' 'NNP' 'NNP' 'WDT' '-NONE-' 'VBZ'\n",
      " 'NNP' 'NNS' ',' 'VBD' 'VBG' 'NN' 'IN' 'PRP$' 'NN' 'NN' 'NNS' 'IN' 'CD'\n",
      " '.']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentences, sentence_tags =[], [] \n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tags = zip(*tagged_sentence)\n",
    "    sentences.append(np.array(sentence))\n",
    "    sentence_tags.append(np.array(tags))\n",
    "print(sentences[5])\n",
    "print(sentence_tags[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(train_sentences, \n",
    " test_sentences, \n",
    " train_tags, \n",
    " test_tags) = train_test_split(sentences, sentence_tags, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10047 46\n"
     ]
    }
   ],
   "source": [
    "words, tags = set([]), set([])\n",
    " \n",
    "for s in train_sentences:\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "\n",
    "for ts in train_tags:\n",
    "    for t in ts:\n",
    "        tags.add(t)\n",
    "\n",
    "print(len(words),len(tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立 词-->index, tag-->index 的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    " \n",
    "tag2index = {t: i + 1 for i, t in enumerate(list(tags))}\n",
    "tag2index['-PAD-'] = 0  # The special value used to padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数字化表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6983, 1692, 1117, 806, 317, 4492, 6390, 4783, 260, 1719, 2961, 1585, 8222, 4906, 6899, 3478, 6243]\n",
      "[4578, 9492, 1968, 4573, 7340, 6649, 823, 4843, 4737, 4950, 5327, 4139, 8222, 926, 8987, 7340, 6400, 9202, 8453, 6992, 6243]\n",
      "[36, 5, 6, 37, 18, 36, 19, 35, 33, 29, 29, 5, 18, 29, 29, 5, 14]\n",
      "[11, 36, 19, 18, 15, 28, 13, 3, 30, 28, 18, 19, 18, 29, 19, 15, 42, 8, 30, 2, 14]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_X, test_sentences_X, train_tags_y, test_tags_y = [], [], [], []\n",
    " \n",
    "for s in train_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    train_sentences_X.append(s_int)\n",
    "\n",
    "for s in test_sentences:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    " \n",
    "    test_sentences_X.append(s_int)\n",
    "\n",
    "for s in train_tags:\n",
    "    train_tags_y.append([tag2index[t] for t in s])\n",
    "\n",
    "for s in test_tags:\n",
    "    test_tags_y.append([tag2index[t] for t in s])\n",
    "\n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
    "print(MAX_LENGTH)  # 271"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用 keras 做 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6983 1692 1117  806  317 4492 6390 4783  260 1719 2961 1585 8222 4906\n",
      " 6899 3478 6243    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[4578 9492 1968 4573 7340 6649  823 4843 4737 4950 5327 4139 8222  926\n",
      " 8987 7340 6400 9202 8453 6992 6243    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[36  5  6 37 18 36 19 35 33 29 29  5 18 29 29  5 14  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "[11 36 19 18 15 28 13  3 30 28 18 19 18 29 19 15 42  8 30  2 14  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    " \n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    " \n",
    "print(train_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(test_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(train_sentences_X[0]))\n",
    "print(len(test_sentences_X[0]))\n",
    "print(len(train_tags_y[0]))\n",
    "print(len(test_tags_y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立 architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    " \n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_categorical(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "cat_train_tags_y = to_categorical(train_tags_y, len(tag2index))\n",
    "print(cat_train_tags_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3131 128\n"
     ]
    }
   ],
   "source": [
    "print(len(cat_train_tags_y),len(cat_train_tags_y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/ner_{}\".format(int(time.time())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3131"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行模型，注意下初始化，否则有时会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2504 samples, validate on 627 samples\n",
      "Epoch 1/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 1.6482 - acc: 0.7603 - val_loss: 0.8111 - val_acc: 0.7978\n",
      "Epoch 2/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.7035 - acc: 0.8028 - val_loss: 0.6828 - val_acc: 0.8043\n",
      "Epoch 3/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.6444 - acc: 0.8215 - val_loss: 0.6488 - val_acc: 0.8208\n",
      "Epoch 4/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.6147 - acc: 0.8262 - val_loss: 0.6209 - val_acc: 0.8205\n",
      "Epoch 5/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.6002 - acc: 0.8253 - val_loss: 0.6144 - val_acc: 0.8244\n",
      "Epoch 6/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5864 - acc: 0.8277 - val_loss: 0.5997 - val_acc: 0.8267\n",
      "Epoch 7/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5740 - acc: 0.8340 - val_loss: 0.5892 - val_acc: 0.8350\n",
      "Epoch 8/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5607 - acc: 0.8433 - val_loss: 0.5773 - val_acc: 0.8458\n",
      "Epoch 9/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5415 - acc: 0.8647 - val_loss: 0.5538 - val_acc: 0.8716\n",
      "Epoch 10/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5091 - acc: 0.8825 - val_loss: 0.5049 - val_acc: 0.8831\n",
      "Epoch 11/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.4511 - acc: 0.8928 - val_loss: 0.4330 - val_acc: 0.8908\n",
      "Epoch 12/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.3725 - acc: 0.9017 - val_loss: 0.3520 - val_acc: 0.9037\n",
      "Epoch 13/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.2948 - acc: 0.9199 - val_loss: 0.2819 - val_acc: 0.9242\n",
      "Epoch 14/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.2286 - acc: 0.9413 - val_loss: 0.2251 - val_acc: 0.9432\n",
      "Epoch 15/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1741 - acc: 0.9595 - val_loss: 0.1827 - val_acc: 0.9563\n",
      "Epoch 16/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1332 - acc: 0.9721 - val_loss: 0.1512 - val_acc: 0.9654\n",
      "Epoch 17/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1023 - acc: 0.9798 - val_loss: 0.1274 - val_acc: 0.9721\n",
      "Epoch 18/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0798 - acc: 0.9845 - val_loss: 0.1112 - val_acc: 0.9743\n",
      "Epoch 19/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0631 - acc: 0.9877 - val_loss: 0.0994 - val_acc: 0.9766\n",
      "Epoch 20/20\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0513 - acc: 0.9900 - val_loss: 0.0921 - val_acc: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b60028208>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "keras.backend.get_session().run(tf.global_variables_initializer()) ##初始化\n",
    "\n",
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), \n",
    "          batch_size=128, epochs=20, validation_split=0.2,callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 3s 3ms/step\n",
      "acc: 97.88673370886275\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_sentences_X, to_categorical(test_tags_y, len(tag2index)))\n",
    "print(f\"{model.metrics_names[1]}: {scores[1] * 100}\")   # acc: 99.09751977804825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 个例预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['running', 'is', 'very', 'important', 'for', 'me', '.'], ['I', 'was', 'running', 'every', 'day', 'for', 'a', 'month', '.']]\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "    \"running is very important for me .\".split(),\n",
    "    \"I was running every day for a month .\".split()\n",
    "]\n",
    "print(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5730 4783 3631 8391 8222  131 6243    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [9566 5340 5730 3718 5283 8222 9492 7242 6243    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n"
     ]
    }
   ],
   "source": [
    "test_samples_X = []\n",
    "for s in test_samples:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    "\n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "print(test_samples_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.41806458e-03 2.09526694e-03 1.12760561e-02 ... 3.17072519e-03\n",
      "   2.91167671e-04 3.01697964e-05]\n",
      "  [3.85120438e-06 1.51414424e-04 8.21110909e-04 ... 9.93145513e-04\n",
      "   3.02747412e-05 4.28981526e-04]\n",
      "  [2.96232629e-05 4.70056169e-04 5.68074989e-04 ... 2.62343604e-03\n",
      "   6.95341587e-05 1.43037367e-04]\n",
      "  ...\n",
      "  [9.99962807e-01 7.65429220e-10 1.07162827e-10 ... 6.33166436e-11\n",
      "   2.01757988e-09 6.23867752e-14]\n",
      "  [9.99942541e-01 1.76822768e-09 1.55685145e-10 ... 1.27181918e-10\n",
      "   4.58827953e-09 1.68707428e-13]\n",
      "  [9.99896049e-01 4.06278611e-09 2.48196269e-10 ... 2.64020694e-10\n",
      "   1.04044124e-08 4.84820029e-13]]\n",
      "\n",
      " [[6.17544913e-07 1.01221405e-04 8.78206105e-04 ... 3.96122487e-04\n",
      "   1.96385026e-05 8.66525690e-04]\n",
      "  [3.16309581e-07 4.27320410e-05 3.45051847e-02 ... 4.56528884e-04\n",
      "   1.12630059e-05 2.42128968e-03]\n",
      "  [1.18084135e-04 1.23343151e-03 3.70652117e-02 ... 2.70214025e-03\n",
      "   1.19684650e-04 2.45355841e-05]\n",
      "  ...\n",
      "  [9.99962807e-01 7.65513875e-10 1.07058223e-10 ... 6.32958755e-11\n",
      "   2.01774553e-09 6.23532259e-14]\n",
      "  [9.99942422e-01 1.76841974e-09 1.55534363e-10 ... 1.27140451e-10\n",
      "   4.58865523e-09 1.68616369e-13]\n",
      "  [9.99896049e-01 4.06318135e-09 2.47956378e-10 ... 2.63933098e-10\n",
      "   1.04052065e-08 4.84552882e-13]]] (2, 128, 47)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_samples_X)\n",
    "print(predictions, predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logits_to_tokens(sequences, index):\n",
    "    token_sequences = []\n",
    "    for categorical_sequence in sequences:\n",
    "        token_sequence = []\n",
    "        for categorical in categorical_sequence:\n",
    "            token_sequence.append(index[np.argmax(categorical)])\n",
    " \n",
    "        token_sequences.append(token_sequence)\n",
    " \n",
    "    return token_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NNP', 'VBZ', 'RB', 'JJ', 'IN', 'PRP', '.', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['PRP', 'VBD', 'VBG', 'DT', 'NN', 'IN', 'DT', 'NN', '.', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
     ]
    }
   ],
   "source": [
    "#  \"running is very important for me .\".split(),\n",
    "#   \"I was running every day for a month .\".split()\n",
    "print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ignore padding 部分的占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    " \n",
    "def ignore_class_accuracy(to_ignore=0):\n",
    "    def ignore_accuracy(y_true, y_pred):\n",
    "        y_true_class = K.argmax(y_true, axis=-1)\n",
    "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
    " \n",
    "        ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
    "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32') * ignore_mask\n",
    "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
    "        return accuracy\n",
    "    return ignore_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 128, 128)          1286272   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128, 512)          788480    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 128, 47)           24111     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 47)           0         \n",
      "=================================================================\n",
      "Total params: 2,098,863\n",
      "Trainable params: 2,098,863\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation\n",
    "from keras.optimizers import Adam\n",
    " \n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(MAX_LENGTH, )))\n",
    "model.add(Embedding(len(word2index), 128))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(tag2index))))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy', ignore_class_accuracy(0)])\n",
    " \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2504 samples, validate on 627 samples\n",
      "Epoch 1/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 1.6804 - acc: 0.7606 - ignore_accuracy: 0.0294 - val_loss: 0.8282 - val_acc: 0.7956 - val_ignore_accuracy: 0.1531\n",
      "Epoch 2/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.7237 - acc: 0.8008 - ignore_accuracy: 0.0064 - val_loss: 0.6918 - val_acc: 0.7955 - val_ignore_accuracy: 0.0981\n",
      "Epoch 3/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.6534 - acc: 0.8205 - ignore_accuracy: 0.1261 - val_loss: 0.6533 - val_acc: 0.8204 - val_ignore_accuracy: 0.1286\n",
      "Epoch 4/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.6214 - acc: 0.8266 - ignore_accuracy: 0.1360 - val_loss: 0.6258 - val_acc: 0.8206 - val_ignore_accuracy: 0.1293\n",
      "Epoch 5/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5968 - acc: 0.8265 - ignore_accuracy: 0.1365 - val_loss: 0.6094 - val_acc: 0.8251 - val_ignore_accuracy: 0.1488\n",
      "Epoch 6/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5835 - acc: 0.8285 - ignore_accuracy: 0.1433 - val_loss: 0.5985 - val_acc: 0.8268 - val_ignore_accuracy: 0.1568\n",
      "Epoch 7/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5717 - acc: 0.8364 - ignore_accuracy: 0.1807 - val_loss: 0.5901 - val_acc: 0.8335 - val_ignore_accuracy: 0.1909\n",
      "Epoch 8/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5584 - acc: 0.8473 - ignore_accuracy: 0.2356 - val_loss: 0.5694 - val_acc: 0.8481 - val_ignore_accuracy: 0.2619\n",
      "Epoch 9/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5451 - acc: 0.8667 - ignore_accuracy: 0.3352 - val_loss: 0.5446 - val_acc: 0.8703 - val_ignore_accuracy: 0.3675\n",
      "Epoch 10/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.5071 - acc: 0.8811 - ignore_accuracy: 0.4054 - val_loss: 0.5036 - val_acc: 0.8802 - val_ignore_accuracy: 0.4177\n",
      "Epoch 11/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.4530 - acc: 0.8905 - ignore_accuracy: 0.4524 - val_loss: 0.4396 - val_acc: 0.8876 - val_ignore_accuracy: 0.4544\n",
      "Epoch 12/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.3864 - acc: 0.8972 - ignore_accuracy: 0.4858 - val_loss: 0.3748 - val_acc: 0.8970 - val_ignore_accuracy: 0.5004\n",
      "Epoch 13/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.3252 - acc: 0.9097 - ignore_accuracy: 0.5485 - val_loss: 0.3200 - val_acc: 0.9131 - val_ignore_accuracy: 0.5799\n",
      "Epoch 14/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.2705 - acc: 0.9284 - ignore_accuracy: 0.6419 - val_loss: 0.2678 - val_acc: 0.9326 - val_ignore_accuracy: 0.6741\n",
      "Epoch 15/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.2180 - acc: 0.9480 - ignore_accuracy: 0.7404 - val_loss: 0.2205 - val_acc: 0.9482 - val_ignore_accuracy: 0.7500\n",
      "Epoch 16/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1688 - acc: 0.9633 - ignore_accuracy: 0.8163 - val_loss: 0.1790 - val_acc: 0.9604 - val_ignore_accuracy: 0.8081\n",
      "Epoch 17/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.1279 - acc: 0.9746 - ignore_accuracy: 0.8729 - val_loss: 0.1463 - val_acc: 0.9676 - val_ignore_accuracy: 0.8431\n",
      "Epoch 18/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0971 - acc: 0.9813 - ignore_accuracy: 0.9063 - val_loss: 0.1238 - val_acc: 0.9722 - val_ignore_accuracy: 0.8657\n",
      "Epoch 19/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0751 - acc: 0.9855 - ignore_accuracy: 0.9277 - val_loss: 0.1084 - val_acc: 0.9745 - val_ignore_accuracy: 0.8768\n",
      "Epoch 20/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0599 - acc: 0.9884 - ignore_accuracy: 0.9418 - val_loss: 0.0977 - val_acc: 0.9763 - val_ignore_accuracy: 0.8852\n",
      "Epoch 21/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0493 - acc: 0.9900 - ignore_accuracy: 0.9501 - val_loss: 0.0905 - val_acc: 0.9776 - val_ignore_accuracy: 0.8919\n",
      "Epoch 22/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0416 - acc: 0.9914 - ignore_accuracy: 0.9570 - val_loss: 0.0842 - val_acc: 0.9787 - val_ignore_accuracy: 0.8969\n",
      "Epoch 23/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0357 - acc: 0.9925 - ignore_accuracy: 0.9624 - val_loss: 0.0804 - val_acc: 0.9796 - val_ignore_accuracy: 0.9012\n",
      "Epoch 24/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0310 - acc: 0.9934 - ignore_accuracy: 0.9668 - val_loss: 0.0773 - val_acc: 0.9805 - val_ignore_accuracy: 0.9059\n",
      "Epoch 25/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0273 - acc: 0.9942 - ignore_accuracy: 0.9710 - val_loss: 0.0748 - val_acc: 0.9811 - val_ignore_accuracy: 0.9087\n",
      "Epoch 26/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0243 - acc: 0.9948 - ignore_accuracy: 0.9738 - val_loss: 0.0733 - val_acc: 0.9812 - val_ignore_accuracy: 0.9091\n",
      "Epoch 27/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0218 - acc: 0.9953 - ignore_accuracy: 0.9765 - val_loss: 0.0720 - val_acc: 0.9815 - val_ignore_accuracy: 0.9106\n",
      "Epoch 28/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0197 - acc: 0.9957 - ignore_accuracy: 0.9785 - val_loss: 0.0709 - val_acc: 0.9819 - val_ignore_accuracy: 0.9129\n",
      "Epoch 29/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0179 - acc: 0.9961 - ignore_accuracy: 0.9804 - val_loss: 0.0712 - val_acc: 0.9817 - val_ignore_accuracy: 0.9116\n",
      "Epoch 30/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0163 - acc: 0.9964 - ignore_accuracy: 0.9821 - val_loss: 0.0694 - val_acc: 0.9822 - val_ignore_accuracy: 0.9142\n",
      "Epoch 31/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0149 - acc: 0.9967 - ignore_accuracy: 0.9835 - val_loss: 0.0696 - val_acc: 0.9822 - val_ignore_accuracy: 0.9145\n",
      "Epoch 32/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0138 - acc: 0.9970 - ignore_accuracy: 0.9848 - val_loss: 0.0691 - val_acc: 0.9823 - val_ignore_accuracy: 0.9147\n",
      "Epoch 33/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0127 - acc: 0.9972 - ignore_accuracy: 0.9862 - val_loss: 0.0683 - val_acc: 0.9824 - val_ignore_accuracy: 0.9151\n",
      "Epoch 34/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0117 - acc: 0.9976 - ignore_accuracy: 0.9878 - val_loss: 0.0689 - val_acc: 0.9824 - val_ignore_accuracy: 0.9149\n",
      "Epoch 35/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0109 - acc: 0.9977 - ignore_accuracy: 0.9886 - val_loss: 0.0683 - val_acc: 0.9826 - val_ignore_accuracy: 0.9162\n",
      "Epoch 36/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0100 - acc: 0.9979 - ignore_accuracy: 0.9896 - val_loss: 0.0693 - val_acc: 0.9824 - val_ignore_accuracy: 0.9150\n",
      "Epoch 37/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0094 - acc: 0.9981 - ignore_accuracy: 0.9904 - val_loss: 0.0686 - val_acc: 0.9825 - val_ignore_accuracy: 0.9157\n",
      "Epoch 38/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0087 - acc: 0.9983 - ignore_accuracy: 0.9914 - val_loss: 0.0692 - val_acc: 0.9826 - val_ignore_accuracy: 0.9162\n",
      "Epoch 39/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0081 - acc: 0.9984 - ignore_accuracy: 0.9921 - val_loss: 0.0694 - val_acc: 0.9826 - val_ignore_accuracy: 0.9161\n",
      "Epoch 40/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0075 - acc: 0.9986 - ignore_accuracy: 0.9931 - val_loss: 0.0704 - val_acc: 0.9824 - val_ignore_accuracy: 0.9153\n",
      "Epoch 41/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0069 - acc: 0.9987 - ignore_accuracy: 0.9937 - val_loss: 0.0708 - val_acc: 0.9826 - val_ignore_accuracy: 0.9158\n",
      "Epoch 42/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0065 - acc: 0.9988 - ignore_accuracy: 0.9941 - val_loss: 0.0700 - val_acc: 0.9826 - val_ignore_accuracy: 0.9158\n",
      "Epoch 43/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0060 - acc: 0.9989 - ignore_accuracy: 0.9946 - val_loss: 0.0716 - val_acc: 0.9824 - val_ignore_accuracy: 0.9150\n",
      "Epoch 44/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0056 - acc: 0.9990 - ignore_accuracy: 0.9951 - val_loss: 0.0716 - val_acc: 0.9825 - val_ignore_accuracy: 0.9152\n",
      "Epoch 45/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0052 - acc: 0.9992 - ignore_accuracy: 0.9959 - val_loss: 0.0731 - val_acc: 0.9824 - val_ignore_accuracy: 0.9149\n",
      "Epoch 46/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0049 - acc: 0.9992 - ignore_accuracy: 0.9962 - val_loss: 0.0722 - val_acc: 0.9824 - val_ignore_accuracy: 0.9151\n",
      "Epoch 47/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0045 - acc: 0.9993 - ignore_accuracy: 0.9967 - val_loss: 0.0722 - val_acc: 0.9824 - val_ignore_accuracy: 0.9148\n",
      "Epoch 48/50\n",
      "2504/2504 [==============================] - 15s 6ms/step - loss: 0.0042 - acc: 0.9994 - ignore_accuracy: 0.9971 - val_loss: 0.0735 - val_acc: 0.9824 - val_ignore_accuracy: 0.9152\n",
      "Epoch 49/50\n",
      "2504/2504 [==============================] - 14s 6ms/step - loss: 0.0039 - acc: 0.9995 - ignore_accuracy: 0.9975 - val_loss: 0.0738 - val_acc: 0.9823 - val_ignore_accuracy: 0.9144\n",
      "Epoch 50/50\n",
      "2504/2504 [==============================] - 14s 6ms/step - loss: 0.0036 - acc: 0.9995 - ignore_accuracy: 0.9977 - val_loss: 0.0741 - val_acc: 0.9822 - val_ignore_accuracy: 0.9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b4eb23550>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs/ignore_ner_{}\".format(int(time.time())))\n",
    "\n",
    "keras.backend.get_session().run(tf.global_variables_initializer())\n",
    "\n",
    "model.fit(train_sentences_X, to_categorical(train_tags_y, len(tag2index)), \n",
    "          batch_size=128, epochs=50, validation_split=0.2, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['VBG', 'VBZ', 'RB', 'JJ', 'IN', 'PRP', '.', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['PRP', 'VBD', 'VBG', 'DT', 'NN', 'IN', 'DT', 'NN', '.', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
     ]
    }
   ],
   "source": [
    "# [['running', 'is', 'very', 'important', 'for', 'me', '.'],\n",
    "#  ['I', 'was', 'running', 'every', 'day', 'for', 'a', 'month', '.']]\n",
    "\n",
    "\n",
    "predictions = model.predict(test_samples_X)\n",
    "print(logits_to_tokens(predictions, {i: t for t, i in tag2index.items()}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
